# -*- coding: utf-8 -*-
"""OpenCV.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pzki7aiX23BwtRMDjQiorNe8V9rUL9PB
"""

import cv2 as cv
import numpy as np
from typing import Tuple, Callable, Optional

# ---------- I/O ----------
def load_image(path: str, color: bool = True) -> np.ndarray:
    flag = cv.IMREAD_COLOR if color else cv.IMREAD_GRAYSCALE
    img = cv.imread(path, flag)
    if img is None:
        raise FileNotFoundError(f"Could not read image: {path}")
    return img

def save_image(path: str, img: np.ndarray) -> None:
    ok = cv.imwrite(path, img)
    if not ok:
        raise IOError(f"Failed to write image: {path}")

# ---------- Conversions ----------
def to_gray(img: np.ndarray) -> np.ndarray:
    return cv.cvtColor(img, cv.COLOR_BGR2GRAY) if img.ndim == 3 else img.copy()

def bgr_to_rgb(img: np.ndarray) -> np.ndarray:
    return cv.cvtColor(img, cv.COLOR_BGR2RGB)

# ---------- Geometry ----------
def resize(img: np.ndarray, size: Tuple[int, int] = None, scale: float = None, interp=cv.INTER_AREA) -> np.ndarray:
    if size is None and scale is None:
        raise ValueError("Provide either size=(w,h) or scale=float.")
    if scale is not None:
        return cv.resize(img, None, fx=scale, fy=scale, interpolation=interp)
    w, h = size
    return cv.resize(img, (w, h), interpolation=interp)

def translate(img: np.ndarray, dx: float, dy: float) -> np.ndarray:
    M = np.float32([[1,0,dx],[0,1,dy]])
    return cv.warpAffine(img, M, (img.shape[1], img.shape[0]))

def rotate(img: np.ndarray, angle_deg: float, center: Tuple[int,int]=None, scale: float=1.0, border=cv.BORDER_REPLICATE) -> np.ndarray:
    (h, w) = img.shape[:2]
    c = center if center else (w//2, h//2)
    M = cv.getRotationMatrix2D(c, angle_deg, scale)
    return cv.warpAffine(img, M, (w, h), borderMode=border)

def perspective_transform(img: np.ndarray, src_pts: np.ndarray, dst_pts: np.ndarray, size: Tuple[int,int]) -> np.ndarray:
    """src_pts/dst_pts: 4x2 float32 arrays; size=(width,height) of output."""
    H = cv.getPerspectiveTransform(src_pts.astype(np.float32), dst_pts.astype(np.float32))
    return cv.warpPerspective(img, H, size)

# ---------- Filtering ----------
def blur_box(img: np.ndarray, k: int = 5) -> np.ndarray:
    return cv.blur(img, (k, k))

def blur_gaussian(img: np.ndarray, k: int = 5, sigma: float = 0) -> np.ndarray:
    k = k if k % 2 == 1 else k+1
    return cv.GaussianBlur(img, (k, k), sigma)

def blur_median(img: np.ndarray, k: int = 5) -> np.ndarray:
    k = k if k % 2 == 1 else k+1
    return cv.medianBlur(img, k)

def bilateral(img: np.ndarray, d: int = 9, sigma_color: int = 75, sigma_space: int = 75) -> np.ndarray:
    return cv.bilateralFilter(img, d, sigma_color, sigma_space)

# ---------- Thresholding & Edges ----------
def threshold_binary(img: np.ndarray, thresh: int = 127, maxval: int = 255) -> np.ndarray:
    gray = to_gray(img)
    _, th = cv.threshold(gray, thresh, maxval, cv.THRESH_BINARY)
    return th

def threshold_otsu(img: np.ndarray, maxval: int = 255) -> np.ndarray:
    gray = to_gray(img)
    _, th = cv.threshold(gray, 0, maxval, cv.THRESH_BINARY + cv.THRESH_OTSU)
    return th

def canny_edges(img: np.ndarray, t1: int = 100, t2: int = 200, aperture: int = 3) -> np.ndarray:
    gray = to_gray(img)
    return cv.Canny(gray, t1, t2, apertureSize=aperture)

# ---------- Morphology ----------
def morphology(img: np.ndarray, op: str = "open", k: int = 3, iters: int = 1) -> np.ndarray:
    ops = {
        "erode": cv.MORPH_ERODE, "dilate": cv.MORPH_DILATE,
        "open": cv.MORPH_OPEN, "close": cv.MORPH_CLOSE,
        "gradient": cv.MORPH_GRADIENT, "tophat": cv.MORPH_TOPHAT, "blackhat": cv.MORPH_BLACKHAT
    }
    if op not in ops:
        raise ValueError(f"op must be one of {list(ops.keys())}")
    kernel = cv.getStructuringElement(cv.MORPH_RECT, (k, k))
    if op in ("erode","dilate"):
        func = cv.erode if op == "erode" else cv.dilate
        return func(img, kernel, iterations=iters)
    return cv.morphologyEx(img, ops[op], kernel, iterations=iters)

# ---------- Drawing ----------
def draw_shapes(img: np.ndarray) -> np.ndarray:
    out = img.copy()
    h, w = out.shape[:2]
    cv.rectangle(out, (10,10), (w//3, h//3), (0,255,0), 2)
    cv.circle(out, (w*2//3, h//3), min(w,h)//10, (255,0,0), 2)
    cv.line(out, (0,h-1), (w-1,0), (0,0,255), 2)
    cv.putText(out, "OpenCV", (10, h-10), cv.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv.LINE_AA)
    return out

# ---------- Contours ----------
def find_contours(binary_img: np.ndarray):
    """Pass a binary image (e.g., from threshold). Returns contours + hierarchy."""
    contours, hier = cv.findContours(binary_img, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    return contours, hier

def draw_contours(img: np.ndarray, contours, color=(0,255,0), thickness=2) -> np.ndarray:
    out = img.copy()
    cv.drawContours(out, contours, -1, color, thickness)
    return out

# ---------- Histograms & Equalization ----------
def histogram_gray(img: np.ndarray) -> np.ndarray:
    gray = to_gray(img)
    hist = cv.calcHist([gray], [0], None, [256], [0,256]).flatten()
    return hist

def equalize_hist_gray(img: np.ndarray) -> np.ndarray:
    return cv.equalizeHist(to_gray(img))

def clahe_gray(img: np.ndarray, clip=2.0, tile=(8,8)) -> np.ndarray:
    clahe = cv.createCLAHE(clipLimit=clip, tileGridSize=tile)
    return clahe.apply(to_gray(img))

# ---------- Template Matching ----------
def template_match(img: np.ndarray, tmpl: np.ndarray, method=cv.TM_CCOEFF_NORMED) -> Tuple[Tuple[int,int], float]:
    res = cv.matchTemplate(img if img.ndim==2 else to_gray(img), to_gray(tmpl), method)
    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)
    if method in (cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED):
        return min_loc, float(min_val)
    return max_loc, float(max_val)

# ---------- Hough ----------
def hough_lines(edges: np.ndarray, rho=1, theta=np.pi/180, threshold=150):
    return cv.HoughLines(edges, rho, theta, threshold)

def hough_circles(gray: np.ndarray, dp=1.2, minDist=30, param1=100, param2=30, minR=0, maxR=0):
    return cv.HoughCircles(gray, cv.HOUGH_GRADIENT, dp, minDist, param1=param1, param2=param2, minRadius=minR, maxRadius=maxR)

# ---------- Video I/O ----------
def process_video(in_path: str, out_path: str, frame_fn: Optional[Callable[[np.ndarray], np.ndarray]] = None) -> None:
    cap = cv.VideoCapture(in_path)
    if not cap.isOpened():
        raise FileNotFoundError(f"Cannot open video: {in_path}")
    fourcc = cv.VideoWriter_fourcc(*"mp4v")
    fps = cap.get(cv.CAP_PROP_FPS) or 25
    w = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))
    out = cv.VideoWriter(out_path, fourcc, fps, (w, h))
    while True:
        ok, frame = cap.read()
        if not ok: break
        proc = frame_fn(frame) if frame_fn else frame
        if proc.ndim == 2:  # make sure it's BGR for writer
            proc = cv.cvtColor(proc, cv.COLOR_GRAY2BGR)
        out.write(proc)
    cap.release(); out.release()

# ---------- Quick Demo (save outputs instead of showing windows) ----------
if __name__ == "__main__":
    # Change this to your test image path
    img_path = "input.jpg"
    img = load_image(img_path)

    # Basic ops
    gray = to_gray(img)
    save_image("out_gray.png", gray)

    small = resize(img, scale=0.5)
    save_image("out_small.png", small)

    rot = rotate(img, 30)
    save_image("out_rotate.png", rot)

    gblur = blur_gaussian(img, k=7)
    save_image("out_gaussian.png", gblur)

    th = threshold_otsu(img)
    save_image("out_otsu.png", th)

    edges = canny_edges(img, 100, 200)
    save_image("out_canny.png", edges)

    mor = morphology(th, op="open", k=5, iters=1)
    save_image("out_morph_open.png", mor)

    cnts, _ = find_contours(mor)
    drawn = draw_contours(img, cnts)
    save_image("out_contours.png", drawn)

    drawn2 = draw_shapes(img)
    save_image("out_draw.png", drawn2)

    eq = equalize_hist_gray(img)
    save_image("out_equalized.png", eq)

    # Template match demo (uses a crop from the image itself)
    h, w = img.shape[:2]
    tmpl = img[h//4: h//4 + h//8, w//4: w//4 + w//8]
    loc, score = template_match(img, tmpl)
    x, y = loc
    boxed = img.copy()
    cv.rectangle(boxed, (x, y), (x+tmpl.shape[1], y+tmpl.shape[0]), (0, 0, 255), 2)
    save_image("out_templatematch.png", boxed)
    print(f"Template match score: {score:.3f} at {loc}")

    # Hough lines (on edges)
    lines = hough_lines(edges)
    hl = img.copy()
    if lines is not None:
        for rho_theta in lines[:100]:  # draw up to 100 lines
            rho, theta = rho_theta[0]
            a, b = np.cos(theta), np.sin(theta)
            x0, y0 = a*rho, b*rho
            pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))
            pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))
            cv.line(hl, pt1, pt2, (0,255,0), 1)
    save_image("out_hough_lines.png", hl)

    # Hough circles (works better on blurred gray)
    circ = img.copy()
    circles = hough_circles(blur_gaussian(gray, 9), dp=1.2, minDist=40)
    if circles is not None:
        circles = np.uint16(np.around(circles))
        for x, y, r in circles[0, :]:
            cv.circle(circ, (x, y), r, (255, 0, 0), 2)
            cv.circle(circ, (x, y), 2, (0, 0, 255), 3)
    save_image("out_hough_circles.png", circ)

    # Simple video processing example (grayscale)
    # process_video("input.mp4", "output_gray.mp4", frame_fn=lambda f: to_gray(f))
    print("Done. Images saved with 'out_*' prefix.")